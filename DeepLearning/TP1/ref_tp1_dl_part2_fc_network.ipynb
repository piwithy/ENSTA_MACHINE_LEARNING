{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2: construction d'un réseau de neurones de classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Imports\n",
    "\n",
    "Pour pouvoir commencer, vous importerez les librairies suivantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras as keras\n",
    "import tools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Loading the dataset avec tensorflow-dataset (tfds)\n",
    "\n",
    "Pour charger les données, nous allons utiliser le projet tensorflow-dataset qui a le mérite de transformer directement les données en objet tf.data.Dataset que je souhaite vous voir utiliser pour différentes raisons exposées en cours Un grand nombre de projet/framework ou simple fichier excel ou csv peut être utilisé pour importer les données.\n",
    "\n",
    "Le jeu de données MNIST est d'environ 12 MB.\n",
    "The MNIST data-set is about 12 MB et sera téléchargé si il n'est pas trouvé dans le chemin par défaut. Le chemin par défaut est ~/tensorflow_datasets/mnist/3.0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "                        'mnist',\n",
    "                        split=['train', 'test'],\n",
    "                        shuffle_files=True,\n",
    "                        as_supervised=True,\n",
    "                        with_info=True,\n",
    "                        )\n",
    "\n",
    "# check if data is a tf.data.Dataset object\n",
    "assert isinstance(ds_train, tf.data.Dataset)\n",
    "assert isinstance(ds_test, tf.data.Dataset)\n",
    "\n",
    "print(ds_train)\n",
    "print(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Analyse et préparation des données avec l'API tf.data.Dataset\n",
    "\n",
    "Les données ont été chargées et regroupent 70.000 images associées à leur indice de chiffre manuscrit. Le jeu de données est déjà séparé en deux sous-ensembles mutuellement exclusifs.\n",
    "\n",
    "### 3.1 - Caractéristiques du dataset\n",
    "Dans cette section, analysez le dictionnaire ds_info pour renseigner les variables ci-dessous\n",
    "- **Nombre d'exemples dans chaque ensemble**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_info)\n",
    "\n",
    "''' START CODE HERE '''\n",
    "num_examples_train =  \n",
    "num_examples_test =  \n",
    "''' END CODE HERE '''\n",
    "\n",
    "\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(num_examples_train))\n",
    "print(\"- Testing-set:\\t\\t{}\".format(num_examples_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Caractéristiques des entrées: dimension, nombre de canaux, nombre de classes, etc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' START CODE HERE '''\n",
    "\n",
    "# shape of one image MNIST\n",
    "img_shape = \n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = \n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = \n",
    "\n",
    "''' END CODE HERE '''\n",
    "\n",
    "\n",
    "\n",
    "print(img_shape)\n",
    "print(num_channels)\n",
    "print(num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Consume the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'API de `tf.data.Dataset` créé un itérable python ce qui le rend facile à utiliser pour obtenir les éléments de la base de données.\n",
    "\n",
    "Voici comment on récupère le premier élément:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prendre le prochain element # créer explicitement un itérateur Python en utilisant iter et en consommant ses éléments en utilisant next :\n",
    "elem = next(iter(ds_test))\n",
    "image = elem[0].numpy()\n",
    "label = elem[1].numpy()\n",
    "\n",
    "print(image.shape)\n",
    "print(label)\n",
    "print(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez l'image avec le label correspondant dans le titre\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' START CODE HERE '''\n",
    "\n",
    "''' END CODE HERE '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - Prétraitement du dataset avec tf.data.Dataset API\n",
    "\n",
    "L'API `tf.data.Dataset` permet de définir assez simplement des chaînes de traitements efficaces efficient. Ainsi, le schéma classique est :\n",
    "- la création d'un dataset source à partir des données d'entrée (déjà fait ici);\n",
    "- la définition et l'application de transformations du datasets pour prétraiter les données;\n",
    "- l'itération sur le dataset et traiter tous les éléments (consume the dataset). \n",
    "\n",
    "L'itération fonctionne un peu comme un streaming, de telle manière que le dataset n'a pas besoin de tenir dans la mémoire de l'ordinateur ou dans celle du GPU.\n",
    "\n",
    "### 3.3.1 - Normaliser tous les éléments\n",
    "Pour cela, il suffit de créer une fonction `normalize_img` et d'utiliser la méthode `map` de l'objet `tf.data.Dataset`. La sortie représente un autre dataset dans lequel à chaque appel, à chaque itération sur l'objet la fonction `normalize_img` sera appliquée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(normalize_img)\n",
    "ds_test  = ds_test.map(normalize_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrivez quelques commandes pour vérifier que la transformation a été faite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' START CODE HERE '''\n",
    "\n",
    "''' END CODE HERE '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 - Mélanger les éléments de la base de données\n",
    "Pour cela, il suffit d'utiliser la méthode `shuffle` de l'objet `tf.data.Dataset`. Il est utile de mélanger les exemples d'apprentissage pour la méthode de recueil/tri des données n'influence pas l'apprentissage. A noter qu'il est inutile de le faire sur la base de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 - Mise en batch des données\n",
    "\n",
    "L'apprentissage des réseaux de neurones fonction par rétropropragation des gradients. Dans le cas des grandes bases de données, il est préférable de ne pas calculer les gradients sur toute la base de données d'apprentissage car le calcul pourrait être extrêment long et difficile à réaliser algorithmiquement. On préfère évaluer ce gradient sur une petite quantité de données mise en batch (de données). Le calcul des gradients est moins précis mais réalisé beaucoup plus souvent. Ce formalisme donne naissance à l'algorithme de descente de gradient stochastique (SGD). L'appel à la méthode `batch` de tensorflow fait cela.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "ds_train = ds_train.batch(batch_size, drop_remainder=True)  # drop_remainder=False epresenting whether the last batch should be dropped in the case it has fewer than batch_size elements; the default behavior is not to drop the smaller batch.\n",
    "ds_test = ds_test.batch(batch_size, drop_remainder=True) # drop_remainder=False epresenting whether the last batch should be dropped in the case it has fewer than batch_size elements; the default behavior is not to drop the smaller batch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire quelques lignes de codes pour vérifier qu'on obtient bien un batch de taille `batch_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem = next(iter(ds_test))\n",
    "image = elem[0].numpy()\n",
    "label = elem[1].numpy()\n",
    "print(image.shape)\n",
    "print(label.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `plot_images` permet l'affichage de 9 éléments de la base de données. Executez là en changeant l'appel pour coller avec vos variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, target_true, target_pred=None):\n",
    "    assert images.shape[0] == target_true.shape[0] == 9\n",
    "\n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i, ..., 0], cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if target_pred is None:\n",
    "            xlabel = \"True: {0}\".format(target_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(target_true[i], target_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "\n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "\n",
    "''' START CODE HERE '''\n",
    "''' END CODE HERE '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Créer et analyser le modèle de réseau de neurones avec Keras\n",
    "\n",
    "La version 2 de Tensorflow intègre désormais Keras (`tf.keras`) facilitant notamment la création d'architecture pour les réseaux de neurones. \n",
    "\n",
    "\n",
    "### 4.1 Créer un réseau simple\n",
    "\n",
    "L'architecture d'un réseau de neurones est définie par un empilement de couches de neurones. Dans Keras, un grand nombre de couches est possible ([layers possibles dans tf.keras.layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/)). On les découvrira au fur et à mesure. Dans ce TP, nous allons nous restreindre aux réseaux de neurones qu'on appelle `Dense` ou `fully connected` c'est à dire que tous les neurones d'une couche sont connectés à tous les neurones de la couche suivante. \n",
    "\n",
    "Cette couche `Dense` implemente l'opération: output = activation(dot(input, kernel) + bias). Cette couche Dense est caractérisée ([lien vers Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) notamment par:\n",
    " - un nombre de neurones;\n",
    " - le type d'activation appliqué à tous les neurones.\n",
    " Un aspect important est la méthode d'initialisation des poids et des biais qu'on explicitera plus tard.\n",
    " \n",
    "Comme les entrées ont une structure spatiale (ce sont des images), et que les couches denses ne traitent pas la structure spatiale (nous verrons la semaine prochaine comment on traite les structures spatiales), il faut modifier les entrées par une couche appelée `Flatten` chargée de vectoriser les images.\n",
    "Ainsi, un modèle à une couche dense prenant en entrée des images de shape: img_shape est défini par la fonction `tf.keras.Sequential`. Vous trouverez [ici](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) les différentes méthodes associés avec le modèle créé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=img_shape),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# deuxième solution équivalente\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Flatten(input_shape=img_shape))\n",
    "# model.add(tf.keras.layers.Dense(num_classes, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Evaluer les performances d'un modèle\n",
    "\n",
    "Au cours de l'apprentissage, il est important d'évaluer les performances. La boucle d'évaluation suivante permet de faire cela pour l'accuracy. Vous noterez l'utilisation de la boucle sur les données de la base de test et des fonctions `tf.equal` et de `tf.reduce_mean`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance du modèle\n",
    "def eval_loop():\n",
    "    # evaluating the model\n",
    "    cor_pred = []\n",
    "    accuracy_tot = []\n",
    "    for i_batch, (img, target_label) in enumerate(ds_test):\n",
    "        # mise en forme\n",
    "        # img = tf.reshape(img, [batch_size, input_img_size])\n",
    "        # target_labels = label  # tf.one_hot(label, num_classes)\n",
    "\n",
    "        # logits = tf.matmul(img, weights) + biases\n",
    "        target_pred = model(img, training=False)\n",
    "\n",
    "        # Now logits is a matrix with num_images rows and num_classes columns, where the element of the $i$'th row and $j$'th column is an estimate of how likely the $i$'th input image is to be of the $j$'th class.\n",
    "        #\n",
    "        # However, these estimates are a bit rough and difficult to interpret because the numbers may be very small or large, so we want to normalize them so that each row of the logits matrix sums to one, and each element is limited between zero and one. This is calculated using the so-called softmax function and the result is stored in y_pred.\n",
    "        # target_pred_ohe = tf.nn.softmax(logits)\n",
    "\n",
    "        # The predicted class can be calculated from the y_pred matrix by taking the index of the largest element in each row.\n",
    "        target_pred = tf.argmax(target_pred, axis=1)\n",
    "\n",
    "        # performance measures\n",
    "        correct_prediction = tf.equal(target_pred, target_label)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        cor_pred.append(correct_prediction)\n",
    "        accuracy_tot.append(accuracy.numpy())\n",
    "\n",
    "    print('model accuracy: {}'.format(np.mean(accuracy_tot)))\n",
    "    # return accuracy_tot\n",
    "\n",
    "#\n",
    "eval_loop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Visualiser les poids du réseau\n",
    "\n",
    "En supplément de la performance, les poids du modèle peuvent également être tracés. \n",
    "Cette représentation donne des informations sur ce qui a été appris par la machine. \n",
    "La fonction `plot_weights_sequential` permet de faire cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(weights, img_shape):\n",
    "\n",
    "        # Get the lowest and highest values for the weights.\n",
    "        # This is used to correct the colour intensity across\n",
    "        # the images so they can be compared with each other.\n",
    "        w_min = np.min(weights)\n",
    "        w_max = np.max(weights)\n",
    "\n",
    "        # Create figure with 3x4 sub-plots,\n",
    "        # where the last 2 sub-plots are unused.\n",
    "        fig, axes = plt.subplots(3, 4)\n",
    "        fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            # Only use the weights for the first 10 sub-plots.\n",
    "            if i < 10:\n",
    "                # Get the weights for the i'th digit and reshape it.\n",
    "                # Note that w.shape == (img_size_flat, 10)\n",
    "                image = weights[:, i].reshape(img_shape)\n",
    "\n",
    "                # Set the label for the sub-plot.\n",
    "                ax.set_xlabel(\"Weights: {0}\".format(i))\n",
    "\n",
    "                # Plot the image.\n",
    "                ax.imshow(image, vmin=w_min, vmax=w_max, cmap='seismic')\n",
    "\n",
    "            # Remove ticks from each sub-plot.\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        # Ensure the plot is shown correctly with multiple plots\n",
    "        # in a single Notebook cell.\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "''' START CODE HERE '''\n",
    "# Get the values for the weights from the TensorFlow variable.\n",
    "weights = model.get_weights()\n",
    "print(len(weights))\n",
    "weights = weights[0]\n",
    "\n",
    "''' END CODE HERE '''\n",
    "\n",
    "# visualisation des poids\n",
    "plot_weights(weights, img_shape[0:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les poids positifs sont rouges et les poids négatifs sont bleus. Ces poids peuvent être intuitivement compris comme des filtres d'images. On verra plus tard l'évolution de ces poids le long de l'apprentissage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Définir la fonction de coût à optimiser\n",
    "\n",
    "Pour que le modèle puisse mieux classer les images en entrée, nous devons d'une manière ou d'une autre modifier les variables pour les poids et les biais. Pour ce faire, il faut définir une fonction de coût mesurant l'adéquation entre la sortie prédite du modèle et à la sortie souhaitée.\n",
    "\n",
    "L'entropie croisée est la fonction classiquement utilisée dans la classification pour actualiser les poids. L'objectif de l'optimisation est donc de minimiser l'entropie croisée afin qu'elle soit aussi proche de zéro que possible en modifiant les poids et les biais du modèle. Vous pouvez vous reporter [ici](https://www.tensorflow.org/api_docs/python/tf/keras/losses) pour voir les différentes fonctions déjà implémentées.\n",
    "\n",
    "TensorFlow dispose d'une fonction intégrée pour calculer l'entropie croisée. Notez qu'elle utilise les valeurs des logits car il calcule également la softmax en interne.\n",
    "\n",
    "Notre modèle calculera sa perte à l'aide de la fonction `tf.keras.losses.SparseCategoricalCrossentropy` qui prend les prédictions de probabilité de classe du modèle et l'étiquette souhaitée, et renvoie la perte moyenne à travers les exemples.\n",
    "La fonction calculant les gradients est aussi donnée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def loss(model, x, y, training):\n",
    "    # training=training is needed only if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    y_ = model(x, training=training)\n",
    "\n",
    "    return loss_fcn(y_true=y, y_pred=y_)\n",
    "\n",
    "l = loss(model, image, label, training=False)\n",
    "print(\"Loss test: {}\".format(l))\n",
    "\n",
    "\n",
    " # Utilisez le contexte tf.GradientTape pour calculer les gradients utilisés pour optimiser votre modèle:\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, training=True)\n",
    "    \n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Définir la méthode d'optimisation\n",
    "\n",
    "Maintenant, il s'agit de définir un optimiseur qui va trouver le minimum de la fonction. Nous connaissons maintenant la descente de gradient stochastique qu'il s'agit de définir avec son `learning rate`.\n",
    "\n",
    "Notez que l'optimisation ,'est pas faite à ce stade. En fait, on défit juste la fonction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_fcn = tf.keras.optimizers.SGD(learning_rate=1.0)\n",
    "\n",
    "def optimize(features, target_labels):\n",
    "\n",
    "    # Compute the loss and the gradient\n",
    "    loss_value, grads = grad(model, features, target_labels)\n",
    "\n",
    "    # mise à jour des paramètres\n",
    "    optimizer_fcn.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # return gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour tester cette fonction, nous allons grâce à ce qui a été mis en place auparavant:\n",
    "- optimiser une fois\n",
    "- évaluer le nouveau coût (la commande est donnée)\n",
    "- évaluer les performances\n",
    "- visualiser les nouveaux poids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' START CODE HERE '''\n",
    "# Get a batch of (images, labels) from the training set\n",
    "(img_batch, label_batch) = next(iter(ds_train))\n",
    "\n",
    "# Call the optimize function\n",
    "optimize(img_batch, label_batch)\n",
    "\n",
    "# Evaluate the loss for each step\n",
    "print(\"Step: {},         Loss: {}\".format(optimizer_fcn.iterations.numpy(), loss(model, img_batch, label_batch, training=True).numpy()))\n",
    "\n",
    "# Evaluate the accuracy\n",
    "eval_loop()\n",
    "\n",
    "# Visualize the weights of the model\n",
    "weights = model.get_weights()\n",
    "weights = weights[0]\n",
    "plot_weights(weights, img_shape[0:2])\n",
    "''' END CODE HERE '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Définir la boucle d'apprentissage\n",
    "\n",
    "### 7.1 - Définir la boucle d'apprentissage avec Tensorflow\n",
    "\n",
    "Une fois qu'on a défini tous les éléments, la boucle d'apprentissage est très simple.\n",
    "Elle prend en entrée le nombre d'epochs `num_epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(num_epochs):\n",
    "    for epoch in range(0, num_epochs, 1):\n",
    "\n",
    "        # Get a batch of training examples.\n",
    "        # img_batch now holds a batch of images and\n",
    "        # label_batch are the true labels for those images.\n",
    "        (img_batch, label_batch) = next(iter(ds_train))\n",
    "\n",
    "        # optimize\n",
    "        optimize(img_batch, label_batch)\n",
    "\n",
    "        print(\"Step: {},         Loss: {}\".format(optimizer_fcn.iterations.numpy(), loss(model, img_batch, label_batch, training=True).numpy()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faites tourner cette fonction pour une epoch et analyser les résultats comme auparavant:\n",
    "- évaluer le nouveau coût (la commande est donnée)\n",
    "- évaluer les performances\n",
    "- visualiser les nouveaux poids \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "\n",
    "''' START CODE HERE '''\n",
    "\n",
    "''' END CODE HERE '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refaites tourner cette fonction pour 10 epoch et analyser les résultats comme auparavant:\n",
    "- évaluer le nouveau coût (la commande est donnée)\n",
    "- évaluer les performances\n",
    "- visualiser les nouveaux poids \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "\n",
    "''' START CODE HERE '''\n",
    "\n",
    "''' END CODE HERE '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 - Keras offre la possibilité de simplifier la démarche\n",
    "\n",
    "En fait, l'API Keras facilite aussi le code de toutes ces étapes. Après avoir défini, l'architecture du modèle avec `Sequential`. Vous devrez le compiler avec la méthode `compile` en choisissant la fonction de coût, l'optimiseur et la métrique de performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "              loss=loss_fcn, \n",
    "              optimizer=optimizer_fcn, \n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'apprentissage sur un nombre d'epochs se fera par un simple appel à la méthode `.fit`.\n",
    "Elle permet de définir un ensemble de validation sur lequel on vient estimer les performances de généralisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "history = model.fit(ds_train, epochs=num_epochs, validation_data=ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle peut alors être sauver dans un fichier (selon deux formats) et éventuellement recharger par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving and Restoring the model\n",
    "# architecture and weights\n",
    "model.save(\"my_keras_model.h5\")\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")\n",
    "\n",
    "# weights only\n",
    "model.save_weights(\"my_keras_weights.ckpt\")\n",
    "model.load_weights(\"my_keras_weights.ckpt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le modèle appris, la méthode `predict` permet de le prédire sur toutes les données de `ds_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pred = model.predict(ds_test)\n",
    "target_label_pred = tf.argmax(target_pred, axis=1).numpy()\n",
    "print(target_label_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - Analyser les résultats\n",
    "Une fois le modèle appris, il s'agit de recenser tous les résultats en affichant (et en les commentant!!!!):\n",
    " - les learning curves;\n",
    " - les métriques de performance;\n",
    " - les poids et les gradients;\n",
    " - les erreurs de classification.\n",
    "\n",
    "### 8.1 learning curves and accuracies\n",
    "\n",
    "Deux possibilités existent pour les métriques de performance:\n",
    "- soit la méthode `evaluate` de Keras\n",
    "- soit la fonction `eval_loop()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curves\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 2)  # set the vertical range to [0-1]\n",
    "plt.show()\n",
    "\n",
    "# métriques de performance:\n",
    "\n",
    "\n",
    "result = model.evaluate(ds_test)\n",
    "print(dict(zip(model.metrics_names, result)))\n",
    "\n",
    "eval_loop()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Commenter ces métriques de performances?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 - Examiner les poids et les gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the weights of the model\n",
    "weights = model.get_weights()\n",
    "weights = weights[0]\n",
    "plot_weights(weights, img_shape[0:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les poids positifs sont en rouge et en bleu pour les négatifs. Par exemple, les poids utilisés pour déterminer si une image montre un chiffre zéro ont une réaction positive (rouge) à une image d'un cercle, et ont une réaction négative (bleu) aux images dont le contenu se trouve au centre du cercle.\n",
    "\n",
    "De même, les pondérations utilisées pour déterminer si une image montre un chiffre 1 réagissent positivement (rouge) à une ligne verticale au centre de l'image, et réagissent négativement (bleu) aux images dont le contenu se trouve autour de cette ligne.\n",
    "\n",
    "Notez que les poids ressemblent surtout aux chiffres qu'ils sont censés reconnaître après quelques itérations. Après un entraînement sur plusieurs milliers d'images, les poids deviennent plus difficiles à interpréter car ils doivent reconnaître de nombreuses variations de la façon dont les chiffres peuvent être écrits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 - Afficher les erreurs de classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pred = model.predict(ds_test)\n",
    "target_label_pred = tf.argmax(target_pred, axis=1).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting example errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [target_label_actual for (img, target_label_actual) in ds_test]\n",
    "\n",
    "target_label_actual = []\n",
    "[ target_label_actual.extend(el.numpy()) for el in tmp]\n",
    "target_label_actual = np.array(target_label_actual)\n",
    "\n",
    "tmp = [img for (img, target_label_actual) in ds_test]\n",
    "imgs = []\n",
    "[ imgs.extend(el.numpy()) for el in tmp]\n",
    "imgs = np.array(imgs)\n",
    "\n",
    "uncorrect = np.where(target_label_pred != target_label_actual)[0]\n",
    "uncorrect = uncorrect[0:9] # juste pour le display\n",
    "plot_images(imgs[uncorrect,:,:,:], target_label_actual[uncorrect], target_pred=target_label_pred[uncorrect])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 3: application à la classification de fonds marins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la suite, vous êtes chargé d'appliquer la démarche décrite dans la partie 2 aux données des images sonar de fonds marins rencontrés précédemment.\n",
    "\n",
    "Si vous ne savez pas commencer, le script ci-dessous pourra certainement vous aider à démarrer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    DATASET_PATH = 'gdrive/My Drive/Colab Notebooks/ex06_supervised_seabedClassification/dataset/imgs/'\n",
    "    LABEL_PATH = 'gdrive/My Drive/Colab Notebooks/ex06_supervised_seabedClassification/dataset/labels/labels.csv'\n",
    "else:\n",
    "    IN_COLAB = False\n",
    "    DATASET_PATH = r'./dataset/imgs/'\n",
    "    LABEL_PATH = r'./dataset/labels/labels.csv'\n",
    "\n",
    "# Charger le fichier CSV\n",
    "dataset_df = pd.read_csv(LABEL_PATH)\n",
    "dataset_df['image_path'] = dataset_df.apply(lambda row: (DATASET_PATH + row[\"id\"]), axis=1)\n",
    "\n",
    "\n",
    "# Charger les images\n",
    "images = np.array([plt.imread(img) for img in dataset_df['image_path'].values.tolist()])\n",
    "label_names = dataset_df['seafloor'].to_numpy()\n",
    "\n",
    "# Création du dataset en objet tf.data.Dataset\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices((images, label_names))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
